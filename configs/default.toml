[build_graphs]
prices = "data/processed/prices.csv"
constituents = "data/processed/constituents.csv"
out = "data/processed/graphs.pt"
membership_mode = "constituents"
window = 20
step = 1
top_k = 5
corr_threshold = ""
min_nodes = 50
feature_mode = "window_plus_summary"
rsi_period = 14
mdy_ticker = "MDY"
normalize = true
symmetric = true
edge_norm = true
edge_weight_mode = "abs"
include_tickers = ["MDY"]
workers = 7
parallel_backend = "threadpool"
joblib_prefer = "threads"
joblib_n_jobs = 0
progress = true

[train]
graphs = "data/processed/graphs.pt"
epochs = 200
batch_size = 32
lr = 0.001
hidden_dim = 128
num_layers = 3
dropout = 0.1
goodness_target = 2.0
goodness_temp = 0.25
ff_layerwise = false
ff_multiscale = true
energy_penalty_weight = 0.0001
energy_penalty_mode = "last"
risk_head_enabled = true
risk_ticker = "MDY"
risk_horizon = 21
risk_loss_weight = 0.1
risk_loss_type = "huber"
risk_standardize = true
neg_mode = "mix"
noise_std = 0.05
device = "mps"
loader_workers = 3
torch_num_threads = 8
torch_num_interop_threads = 2
dataloader_persistent_workers = true
dataloader_prefetch_factor = 2
dataloader_pin_memory = false
dataloader_mp_context = "spawn"
seed = 7
log_csv = "reports/ff_train.csv"
plot_path = "reports/ff_train.png"
save_model = "runs/ff_model.pt"
auto_tune_batch = true
auto_tune_max_batch = 32
auto_tune_factor = 2
auto_tune_min_batch = 1
neg_warmup_epochs = 10
neg_mix_start = 0.0
neg_mix_end = 0.8
neg_mix_ramp_epochs = 40
neg_gate_margin = 1.0
grad_clip = 1.0
layerwise_neg_mode = "shuffle+noise"
layerwise_noise_std = 0.12
layerwise_hall_corr = 0.0
layerwise_hall_mean = 0.01
layerwise_hall_std = 0.01

# Hallucinated negatives (used when neg_mode = "hallucinate")
hallucinate_steps = 4
hallucinate_lr = 0.03
hallucinate_l2 = 0.04
hallucinate_mean = 0.006
hallucinate_std = 0.006
hallucinate_corr = 0.25
hallucinate_clamp_std = 3.0
hallucinate_node_fraction = 0.4
hallucinate_node_min = 15

[benchmark]
epochs = 5
batch_size = 32
eval_frac = 0.2
neg_mode = "mix"
eval_neg_mode = "shuffle"
timing_warmup_epochs = 1
out_csv = "reports/benchmark.csv"
plot_path = "reports/benchmark_speed_sep.png"
bar_plot_path = "reports/benchmark.png"

[sweep]
epochs = 3
batch_size = 32
eval_frac = 0.2
eval_neg_mode = "shuffle"
timing_warmup_epochs = 1
out_csv = "reports/ff_sweep.csv"
modes = ["ff_layerwise", "ff_e2e"]
goodness_temp = [0.2, 0.25]
goodness_target = [1.5, 2.0]
neg_mix_end = [0.5, 0.7]
hall_steps = [1, 2]
hall_lr = [0.02, 0.03]
hall_node_fraction = [0.2]
top_k = 10
parallel_workers = 1
parallel_backend = "process"
parallel_mp_context = "spawn"
parallel_force_cpu = true
worker_torch_threads = 1
worker_torch_interop_threads = 1
worker_loader_workers = 0

[sweep_layerwise]
epochs = 3
batch_size = 32
eval_frac = 0.2
eval_neg_mode = "shuffle"
timing_warmup_epochs = 1
out_csv = "reports/ff_sweep_layerwise.csv"
modes = ["ff_layerwise"]
goodness_temp = [0.2, 0.25]
goodness_target = [1.5, 2.0]
neg_mix_end = [0.5, 0.7]
hall_steps = [1, 2]
hall_lr = [0.02, 0.03]
hall_node_fraction = [0.2]
layerwise_neg_mode = ["shuffle+noise"]
layerwise_noise_std = [0.08, 0.12, 0.16]
layerwise_hall_corr = [0.0]
layerwise_hall_mean = [0.01]
layerwise_hall_std = [0.01]
top_k = 10

[sweep_tune]
out_csv = "reports/sweep_parallel_tune.csv"
device = "cpu"
epochs = 2
batch_size = 32
sample_graphs = 256
max_batches = 5
neg_mode = "shuffle"
parallel_backend = "process"
parallel_mp_context = "spawn"
parallel_workers = [1, 2, 3, 4]
worker_torch_threads = [1, 2]
worker_torch_interop_threads = [1]
worker_loader_workers = [0, 1]
apply = true
apply_to = "configs/default.toml"
apply_section = "sweep"
apply_min_improvement = 0.1
apply_backup = true
apply_backup_suffix = ".bak"
isolate_thread_settings = true

[train.hallucinate_curriculum]
enabled = true
start_epoch = 5
ramp_epochs = 30
steps_start = 1
steps_end = 4
lr_start = 0.02
lr_end = 0.03
l2_start = 0.08
l2_end = 0.04
corr_start = 0.3
corr_end = 0.25
node_fraction_start = 0.2
node_fraction_end = 0.4
node_min_start = 10
node_min_end = 15

[scenario_book]
num_scenarios = 50
target_ticker = "MDY"
target_drop = -0.10
constraint_weight = 20.0
adaptive = true
target_hit_rate = 0.6
target_tolerance = 0.01
max_adapt_steps = 40
diag_out = "reports/scenario_constraint_diagnostics.csv"
out = "reports/scenario_book.csv"
